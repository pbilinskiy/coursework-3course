\documentclass[main.tex]{subfile}



\begin{document}
	\section{Випадок $A= \partial f$}
	Важливий частинний випадок нашої задачі - коли $A(\cdot) = \partial f(\cdot)$ - субградієнт. Відомо, що якщо $f$ - власна функція (proper function), то $\partial f(\cdot)$ - монотонний оператор \cite{bauschke}.  
	
	Одним із головних застосувань задачі є пошук екстремумів опуклих недиференційовних функцій. Аналогом теореми Ферма є таке твердження \cite{bauschke}:
	\begin{theorem}[Теорема Ферма для опуклих функцій]
		Нехай $f \in \Gamma_0(\Hil)$, тоді
		\[\arg \min f = \text{zer }  \partial f = \{x \in \mathcal{H} \mid 0 \in \partial f(x) \}\]
	\end{theorem}

    Всюди надалі будемо говорити про мінімізацію цільової функції:
     \begin{equation}
     	f \rightarrow \min
     	\label{minimum_problem}
     \end{equation}.
    
    Зазвичай ми робимо такі припущеня про $f(x)$:
    \begin{enumerate}
    	\item $f : \Hil \rightarrow (-\infty, \infty]$ - власна (proper), замкнена і опукла.
    	\item Множина розв'язків задачі \ref{minimum_problem} є непорожньою.
    	\item МИ маємо доступ до оракула, який для довільної точки $x$ видає 
    	випадковий субградієнт $g(x) \in \partial f(x)$. 
    \end{enumerate}

    \subsection{Градієнтний спуск}
    У випадку гладкої функції існує градієнтний метод пошуку екстремуму. Ітераційний процес методу для задачі мінімізації має вигляд:
    \[ x_{n+1} = x_n -\lambda \nabla f(x_n) \]
    , де  $ \lambda $ вибирається таким чином, щоби гарантувати збіжність методу. Також є різні оцінки швидкодії градієнтного спуску, які потребують, щоби $\lambda$ вибиралася за певною формулою. 
    
    По аналогії, можемо розглянути субградієнтний метод:
    \begin{equation}
    	x_{n+1} = x_n - \lambda g(x_n) \label{subgrad_descend}
    \end{equation}
    Отримали, замінивши $\nabla f$ на $g(x_n) \in \partial f(x_n)$ - довільний субградієнт.
    Для цього алгоритму справджується така теорема:
    \begin{theorem}[Збіжність алгоритму субградієнтного спуску]
    	Нехай окрім згаданих вище умов справджується:
    	\begin{enumerate}
    		\item Існує така стала $M > 0$, що для всіх $x \in \R^n$ і для всіх $g(x) \in \partial f(x)$ виконується
    		\[ \|g(x)\|_2 \leq M \]
    	\end{enumerate}
    	Нехай $x_*$ - найближчий розв'язок до $x_0$, $R_0 = \| x_0 - x_*\|_2$ та 
    	$\lambda = \frac{R_0}{M\sqrt{N+1}}$. Тоді через $N$ ітерацій градієнтного спуску маємо
    	\[ f(\overline{x}_N) - f(x_*) \leq \frac{MR_0}{\sqrt{N+1}}\]
    	де $\overline{x}_N \frac{1}{N+1} \sum_{k=0}^{N} x_k$. Окрім того, для досягнення точності $\epsilon$ по функції $(f(\overline{x}_N) - f(x_*))$ метод достатньо запустити на $N = O(\frac{M^2R_0^2}{\epsilon^2})$
    \end{theorem}
    
    \subsection{Проксимальний алгоритм}
    Нехай цільова функція розкладається є сумою двох частин, і задача має вигляд:
    \[F(x) = f(x) + R(x) \rightarrow \min_{x \in \R^n}\]
    за теоремою Ферма та властивостями субградієнта, ця задача еквівалентна такій:
    \[0 \in Ax + Bx\text{, де } A = \partial f(x), B = \partial R(x)\]
    Тоді використовується проксимальний алгоритм, який в класичному випадку має вигляд:
    \[ x_{n+1} = prox_{\lambda R}(x_n - \lambda \nabla f(x_n)) \text{, де }  prox_R(x) = \arg \min_{y \in \R^n} \{R(y) + \frac{1}{2}\|y-x\|_2^2  \}\] 
     
     Можна отримати субградієнтний проксимальний метод, замінивши градієнт $\nabla (\cdot)$ на довільний субградієнт $g \in \partial (\cdot)$:
    \[ x_{n+1} = prox_{\lambda R}(x_n - \lambda g (x_n))\]
    
    Зазвичай цей алгоритм застосовують тоді, коли можна легко обчислити $prox_R$.
    
    \subsection{Проекційний алгоритм для пошуку умовного екстремуму}
    Класичний вигляд ітераційного процесу:
    \[ x_{n+1} = P_C(x_n - \lambda_n \nabla f(x_n)) \]
    Як і раніше, переходимо від градієнтів $\nabla f(x_n)$ до субградієнтів $g(x_n) \in \partial f(x_n)$, отримаємо проекційний субградієнтний метод:
    
    \[ x_{n+1} = P_C(x_n - \lambda_n g(x_n)) \]
    
    
    Можна сформулювати теорему про збіжність, не враховуючи стохастичну природу величини $g(x_n)$. У книзі \cite{amir_beck} наведений результат, згідно з яким метод буде збігатися незалежно від того, яким буде $g(x_n)$. Також ця теорема дає оцінку швидкості збіжності.
    
    Інший підхід - розглянути послідовність ітерацій алгоритму $(x_n)$ як послідовність випадкових величин. У книзі \cite{amir_beck} доводена збіжність послідовності {\itshape найкращих отриманих значень}:
    \[ \mathbb{E}(f_{best}^{(n)}) \rightarrow f_{opt} \text{ при } k \rightarrow \infty\]
    
\end{document}